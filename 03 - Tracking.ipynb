{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 12, 8\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "\n",
    "vgg = VGG16(include_top=False, weights=\"imagenet\")\n",
    "vgg.trainable = False\n",
    "\n",
    "dense = load_model(\"modele-VGG16\") # ou 'modele-VGG16.h5'\n",
    "modele = Sequential([\n",
    "    Input((227, 227, 3)),\n",
    "    vgg,\n",
    "    dense\n",
    "], name=\"complet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "NOM = \"BowlPlace1Subject1\"\n",
    "VIDEO = join(\"VIDEOS\", NOM + \".mp4\")\n",
    "BOITE = join(\"GT\", NOM + \"_2_bboxes.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture des boites fournies\n",
    "Lit le fichier contenant les informations de reconnaissance d'objets pour avoir un point de départ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists, join\n",
    "from typing import List, Tuple\n",
    "import csv\n",
    "\n",
    "def lecture_information_boite_englobante(nom: str) -> List[List[Tuple[int, int, int, int]]]:\n",
    "    \"\"\" Lit les boites englobante fournies pour l'exemple. \"\"\"\n",
    "    resultats = list()\n",
    "    \n",
    "    with open(join(\"GT\", nom + \"_2_bboxes.txt\"), \"r\") as fichier:\n",
    "        lecteur = csv.reader(fichier, delimiter=\" \")\n",
    "\n",
    "        for ligne in lecteur:\n",
    "            frame_nb = int(ligne[0])\n",
    "            boite_nb = int(ligne[1])\n",
    "            boites = list()\n",
    "            for i in range(boite_nb):\n",
    "                boite = (int(ligne[i * 4 + 2]), int(ligne[i * 4 + 3]), int(ligne[i * 4 + 4]), int(ligne[i * 4 + 5]))\n",
    "                boites.append(boite)\n",
    "            resultats.append(boites)\n",
    "    \n",
    "    return resultats\n",
    "\n",
    "boites_englobantes = lecture_information_boite_englobante(NOM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche de l'objet sur la prochaine image\n",
    "À partir de la zone désignée dans l'image précédante, tente de retrouver l'objet dans la nouvelle image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def evaluation_boite(image: Image, boites: list) -> np.array:\n",
    "    \"\"\" Évalue les boites englobantes.\n",
    "    Passer plusieurs boites englobantes en même temps permet d'accélérer le calcul.\n",
    "    \"\"\"\n",
    "    print(f\"evaluation de {len(boites)} boites\")\n",
    "    extraits = list(np.asarray(image\\\n",
    "        .resize((227, 227), box=((boite[0], boite[1], boite[0] + boite[2], boite[1] + boite[3]))))\n",
    "        for boite in boites)\n",
    "    return modele.predict(np.array(extraits))\n",
    "\n",
    "def tracking_move_box(image: Image.Image, boite_pre: (int, int, int, int), categorie: int) -> (int, int, int, int):\n",
    "    \"\"\"Calcul le mouvement de la boite.\n",
    "    @param image: image courante\n",
    "    @param boite_pre: ancienne boite englobante\n",
    "    @return la nouvelle position de la boite englobante\n",
    "    \"\"\"\n",
    "    assert(isinstance(boite_pre, tuple))\n",
    "    \n",
    "    valeurs = evaluation_boite(image, (boite_pre,))\n",
    "    evaluations = {boite_pre: valeurs[0][categorie]}  # categorie\n",
    "    meilleur_pos = boite_pre\n",
    "    #print(meilleur_pos, valeur[categorie])\n",
    "    #print(boite_cible, valeurs[1][categorie])\n",
    "\n",
    "    # Modifications légères de la boite en maximisant la correspondance à la catégorie.\n",
    "    # la déplacer un peu et réessayer\n",
    "    # Méthode diamand sur 4D (x, y, w, h) ou (x, y, ratio, zoom)\n",
    "    pas = 16\n",
    "    while pas >= 8:\n",
    "        # Liste des positions évaluées mais pas leurs voisins\n",
    "        exploration = [meilleur_pos]\n",
    "        # Liste des positions évaluées et aussi leurs voisins\n",
    "        explores = set()\n",
    "\n",
    "        while len(exploration) > 0 and (len(explores) < 4 or \\\n",
    "            max(explores, key=evaluations.__getitem__) < max(exploration, key=evaluations.__getitem__)):\n",
    "            # Une position plus favorable nécessite d'étudier ses voisins\n",
    "            pos = max(exploration, key=evaluations.__getitem__)\n",
    "            exploration.remove(pos)\n",
    "\n",
    "            # propositions de nouvelles boites englobantes\n",
    "            propositions = list(boite_v\n",
    "                for boite_v in boites_voisines(pos, image.size, pas=pas)\n",
    "                    if boite_v not in evaluations.keys())\n",
    "            propositions = list(boite_v for boite_v in propositions if boite_v not in evaluations)\n",
    "\n",
    "            # évalue toutes les boites proposées\n",
    "            valeurs = evaluation_boite(image, propositions)\n",
    "            for i, boite_v in enumerate(propositions):\n",
    "                # note pour la catégorie considérée\n",
    "                evaluations[boite_v] = valeurs[i][categorie]\n",
    "\n",
    "            exploration.extend(propositions)\n",
    "            explores.add(pos)\n",
    "\n",
    "        meilleur_pos = max(explores, key=evaluations.__getitem__)\n",
    "        print(\"meilleur\", meilleur_pos, evaluations[meilleur_pos])\n",
    "        pas /= 2\n",
    "    return meilleur_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_leger(image: Image.Image, boite_pre: (int, int, int, int), categorie: int) -> (int, int, int, int):\n",
    "    pas = 2\n",
    "    demi_taille = 5\n",
    "    positions = list()\n",
    "    evaluations = {}\n",
    "    positions.append(boite_pre)\n",
    "    for dx in range(-demi_taille, demi_taille, pas):\n",
    "        for dy in range(-demi_taille, demi_taille, pas):\n",
    "            positions.append((boite_pre[0] + dx, boite_pre[1] + dy, boite_pre[2], boite_pre[3]))\n",
    "    valeurs = evaluation_boite(image, positions)\n",
    "    for i, boite_v in enumerate(positions):\n",
    "        evaluations[boite_v] = valeurs[i][categorie]\n",
    "    return max(positions, key=evaluations.__getitem__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "* frame 0\n",
      "* frame 1\n",
      "* frame 2\n",
      "* frame 3\n",
      "* frame 4\n",
      "* frame 5\n",
      "* frame 6\n",
      "* frame 7\n",
      "* frame 8\n",
      "* frame 9\n",
      "* frame 10\n",
      "* frame 11\n",
      "* frame 12\n",
      "* frame 13\n",
      "* frame 14\n",
      "* frame 15\n",
      "* frame 16\n",
      "* frame 17\n",
      "* frame 18\n",
      "* frame 19\n",
      "* frame 20\n",
      "* frame 21\n",
      "* frame 22\n",
      "* frame 23\n",
      "* frame 24\n",
      "* frame 25\n",
      "* frame 26\n",
      "* frame 27\n",
      "* frame 28\n",
      "* frame 29\n",
      "* frame 30\n",
      "* frame 31\n",
      "* frame 32\n",
      "* frame 33\n",
      "* frame 34\n",
      "* frame 35\n",
      "* frame 36\n",
      "* frame 37\n",
      "* frame 38\n",
      "* frame 39\n",
      "* frame 40\n",
      "* frame 41\n",
      "* frame 42\n",
      "* frame 43\n",
      "* frame 44\n",
      "* frame 45\n",
      "* frame 46\n",
      "* frame 47\n",
      "* frame 48\n",
      "* frame 49\n",
      "* frame 50\n",
      "* frame 51\n",
      "* frame 52\n",
      "* frame 53\n",
      "* frame 54\n",
      "* frame 55\n",
      "* frame 56\n",
      "* frame 57\n",
      "* frame 58\n",
      "* frame 59\n",
      "* frame 60\n",
      "* frame 61\n",
      "* frame 62\n",
      "* frame 63\n",
      "* frame 64\n",
      "* frame 65\n",
      "* frame 66\n",
      "* frame 67\n",
      "* frame 68\n",
      "* frame 69\n",
      "* frame 70\n",
      "* frame 71\n",
      "* frame 72\n",
      "* frame 73\n",
      "* frame 74\n",
      "* frame 75\n",
      "* frame 76\n",
      "* frame 77\n",
      "* frame 78\n",
      "* frame 79\n",
      "* frame 80\n",
      "* frame 81\n",
      "* frame 82\n",
      "* frame 83\n",
      "* frame 84\n",
      "* frame 85\n",
      "* frame 86\n",
      "* frame 87\n",
      "* frame 88\n",
      "* frame 89\n",
      "* frame 90\n",
      "* frame 91\n",
      "* frame 92\n",
      "* frame 93\n",
      "* frame 94\n",
      "* frame 95\n",
      "evaluation de 1 boites\n",
      "tracking pour la catégorie 0\n",
      "* frame 96\n",
      "boite_pre (864, 382, 86, 110)\n",
      "evaluation de 26 boites\n",
      "ajustement de (864, 382, 86, 110) à (864, 382, 86, 110)\n",
      "score: 0.6452173913043479\n",
      "* frame 97\n",
      "boite_pre (864, 382, 86, 110)\n",
      "evaluation de 26 boites\n",
      "ajustement de (864, 382, 86, 110) à (859, 377, 86, 110)\n",
      "score: 0.4160616720305366\n",
      "* frame 98\n",
      "boite_pre (859, 377, 86, 110)\n",
      "evaluation de 26 boites\n",
      "ajustement de (859, 377, 86, 110) à (854, 372, 86, 110)\n",
      "score: 0.3297722800112454\n",
      "* frame 99\n",
      "boite_pre (854, 372, 86, 110)\n",
      "evaluation de 26 boites\n",
      "ajustement de (854, 372, 86, 110) à (854, 372, 86, 110)\n",
      "score: 0.31843446039833256\n",
      "* frame 100\n",
      "boite_pre (854, 372, 86, 110)\n",
      "evaluation de 26 boites\n",
      "ajustement de (854, 372, 86, 110) à (854, 372, 86, 110)\n",
      "score: 0.3044496487119438\n",
      "* frame 101\n",
      "boite_pre (854, 372, 86, 110)\n",
      "evaluation de 26 boites\n",
      "ajustement de (854, 372, 86, 110) à (854, 372, 86, 110)\n",
      "score: 0.3044496487119438\n",
      "* frame 102\n",
      "boite_pre (854, 372, 86, 110)\n",
      "evaluation de 26 boites\n",
      "ajustement de (854, 372, 86, 110) à (849, 367, 86, 110)\n",
      "score: 0.34696345149766417\n",
      "* frame 103\n",
      "boite_pre (849, 367, 86, 110)\n",
      "evaluation de 26 boites\n",
      "ajustement de (849, 367, 86, 110) à (844, 362, 86, 110)\n",
      "score: 0.3014018691588785\n",
      "* frame 104\n",
      "boite_pre (844, 362, 86, 110)\n",
      "evaluation de 26 boites\n",
      "ajustement de (844, 362, 86, 110) à (843, 357, 86, 110)\n",
      "score: 0.28711727325245523\n",
      "* frame 105\n",
      "boite_pre (843, 357, 86, 110)\n",
      "evaluation de 26 boites\n",
      "ajustement de (843, 357, 86, 110) à (846, 352, 86, 110)\n",
      "score: 0.29781825884346536\n",
      "* frame 106\n",
      "boite_pre (846, 352, 86, 110)\n",
      "evaluation de 26 boites\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluateBBox import *\n",
    "\n",
    "assert exists(VIDEO), \"le fichier vidéo n'existe pas\"\n",
    "\n",
    "frame = 0\n",
    "video = cv2.VideoCapture(VIDEO)\n",
    "tracking = False\n",
    "categorie = 0\n",
    "sequence = list()\n",
    "\n",
    "while video.isOpened():\n",
    "    # print(f\"* frame {frame}\")\n",
    "    ret, f = video.read()\n",
    "    if ret == False:\n",
    "        print(\"erreur\")\n",
    "        break\n",
    "\n",
    "    f = cv2.cvtColor(f, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(f)\n",
    "        \n",
    "    # découper une boite\n",
    "    if not tracking and len(boites_englobantes[frame]) > 0:\n",
    "        tracking = True\n",
    "        sequence.append(boites_englobantes[frame][0])\n",
    "        valeurs = evaluation_boite(image, (sequence[-1],))\n",
    "        categorie = np.argmax(valeurs[0])\n",
    "        print(\"tracking pour la catégorie\", categorie)\n",
    "        \n",
    "    elif tracking:\n",
    "        boite_pre = sequence[-1]\n",
    "        print(f\"boite_pre {boite_pre}\")\n",
    "        boite_cible = boites_englobantes[frame][0]\n",
    "        \n",
    "        meilleur_pos = tracking_move_box(image, boite_pre, categorie)\n",
    "        # meilleur_pos = tracking_leger(image, boite_pre, categorie)\n",
    "\n",
    "        print(f\"ajustement de {boite_pre} à {meilleur_pos}\")\n",
    "        print(f\"score: {IoU(boite_cible, meilleur_pos)}\")\n",
    "        sequence.append(meilleur_pos)\n",
    "        x, y, w, h = meilleur_pos\n",
    "\n",
    "        ff = f.copy()\n",
    "        cv2.rectangle(ff, (x, y), (x+w, y+h), (0, 255, 0), 2) \n",
    "        cv2.imshow(\"frame \"+str(frame), ff)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    else:\n",
    "        sequence.append(None)\n",
    "    frame += 1\n",
    "\n",
    "print(\"out\")\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}